{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d1da9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, WhitespaceTokenizer\n",
    "import warnings\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ca89c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset/dataset_generated.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbb80245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324778\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0287157f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the author that the guard likes smiles . <eos>\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6697e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"no authors that the guards like have ever been popular . <eos>\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37a0b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = lines.index(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1699b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1 = []\n",
    "judgement1 = []\n",
    "for i in range(len(lines[:k])):\n",
    "    line = lines[i].split(\".\")\n",
    "    sent = line[0]\n",
    "    sentences1.append(sent)\n",
    "    correct = 0\n",
    "    if (i % 2) == 0:\n",
    "        correct = 1\n",
    "    judgement1.append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f2c0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(list(zip(sentences1, judgement1)), columns =['Sentence', 'Judgement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50ce127d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the author that the guard likes laughs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the author that the guard likes laugh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the author that the guard likes swims</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the author that the guard likes swim</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the author that the guard likes smiles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294515</th>\n",
       "      <td>the bankers knew the consultants hated herself</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294516</th>\n",
       "      <td>the bankers knew the consultants doubted thems...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294517</th>\n",
       "      <td>the bankers knew the consultants doubted himself</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294518</th>\n",
       "      <td>the bankers knew the consultants doubted thems...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294519</th>\n",
       "      <td>the bankers knew the consultants doubted herself</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentence  Judgement\n",
       "0                 the author that the guard likes laughs           1\n",
       "1                  the author that the guard likes laugh           0\n",
       "2                  the author that the guard likes swims           1\n",
       "3                   the author that the guard likes swim           0\n",
       "4                 the author that the guard likes smiles           1\n",
       "...                                                   ...        ...\n",
       "294515    the bankers knew the consultants hated herself           0\n",
       "294516  the bankers knew the consultants doubted thems...          1\n",
       "294517  the bankers knew the consultants doubted himself           0\n",
       "294518  the bankers knew the consultants doubted thems...          1\n",
       "294519  the bankers knew the consultants doubted herself           0\n",
       "\n",
       "[294520 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ea35eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2 = []\n",
    "judgement2 = []\n",
    "for i in range(len(lines[k:])):\n",
    "    j = k + i\n",
    "    line = lines[j].split(\".\")\n",
    "    sent = line[0]\n",
    "    sentences2.append(sent)\n",
    "    correct = 0\n",
    "    if (j % 3) == 1:\n",
    "        correct = 1\n",
    "    judgement2.append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "392fa7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(list(zip(sentences2, judgement2)), columns =['Sentence', 'Judgement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6a00e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no authors that the guards like have ever been...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the authors that no guards like have ever been...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>most authors that the guards like have ever be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no authors that the guards like have ever been...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the authors that no guards like have ever been...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30253</th>\n",
       "      <td>some shows will ever be ignored</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30254</th>\n",
       "      <td>many shows will ever be ignored</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30255</th>\n",
       "      <td>few shows will ever get old</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30256</th>\n",
       "      <td>some shows will ever get old</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30257</th>\n",
       "      <td>many shows will ever get old</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30258 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence  Judgement\n",
       "0      no authors that the guards like have ever been...          1\n",
       "1      the authors that no guards like have ever been...          0\n",
       "2      most authors that the guards like have ever be...          0\n",
       "3      no authors that the guards like have ever been...          1\n",
       "4      the authors that no guards like have ever been...          0\n",
       "...                                                  ...        ...\n",
       "30253                   some shows will ever be ignored           0\n",
       "30254                   many shows will ever be ignored           0\n",
       "30255                       few shows will ever get old           1\n",
       "30256                      some shows will ever get old           0\n",
       "30257                      many shows will ever get old           0\n",
       "\n",
       "[30258 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37d6c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sent = sentences1 + sentences2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70faf983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324778"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3168cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sent_tkn = []\n",
    "for sent in list_sent:\n",
    "    list_sent_tkn.append(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "010339ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324778"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_sent_tkn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "936537f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'author', 'that', 'the', 'guard', 'likes', 'swims']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sent_tkn[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bad45d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(list_sent_tkn, min_count=1, vector_size= 50, workers=3, window=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a9c5db05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "words = list(w2v_model.wv.index_to_key)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e132337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'that',\n",
       " 'are',\n",
       " 'is',\n",
       " 'like',\n",
       " 'admire',\n",
       " 'love',\n",
       " 'hate',\n",
       " 'ever',\n",
       " 'likes',\n",
       " 'hates',\n",
       " 'admires',\n",
       " 'loves',\n",
       " 'taxi',\n",
       " 'old',\n",
       " 'themselves',\n",
       " 'people',\n",
       " 'to',\n",
       " 'young',\n",
       " 'tall',\n",
       " 'short',\n",
       " 'popular',\n",
       " 'executives',\n",
       " 'drivers',\n",
       " 'dancers',\n",
       " 'guards',\n",
       " 'ministers',\n",
       " 'chefs',\n",
       " 'architects',\n",
       " 'skaters',\n",
       " 'parents',\n",
       " 'assistants',\n",
       " 'have',\n",
       " 'will',\n",
       " 'skater',\n",
       " 'parent',\n",
       " 'executive',\n",
       " 'assistant',\n",
       " 'driver',\n",
       " 'dancer',\n",
       " 'minister',\n",
       " 'architect',\n",
       " 'chef',\n",
       " 'guard',\n",
       " 'herself',\n",
       " 'himself',\n",
       " 'unpopular',\n",
       " 'joy',\n",
       " 'new',\n",
       " 'bad',\n",
       " 'good',\n",
       " 'teachers',\n",
       " 'consultants',\n",
       " 'senators',\n",
       " 'managers',\n",
       " 'officers',\n",
       " 'customers',\n",
       " 'farmers',\n",
       " 'surgeons',\n",
       " 'pilots',\n",
       " 'authors',\n",
       " 'be',\n",
       " 'of',\n",
       " 'laughs',\n",
       " 'smiles',\n",
       " 'laugh',\n",
       " 'swims',\n",
       " 'swim',\n",
       " 'smile',\n",
       " 'from',\n",
       " 'author',\n",
       " 'teacher',\n",
       " 'surgeon',\n",
       " 'pilot',\n",
       " 'senator',\n",
       " 'officer',\n",
       " 'customer',\n",
       " 'manager',\n",
       " 'farmer',\n",
       " 'consultant',\n",
       " 'no',\n",
       " 'few',\n",
       " 'been',\n",
       " 'hated',\n",
       " 'doubted',\n",
       " 'embarrassed',\n",
       " 'congratulated',\n",
       " 'injured',\n",
       " 'disguised',\n",
       " 'hurt',\n",
       " 'shows',\n",
       " 'novels',\n",
       " 'paintings',\n",
       " 'poems',\n",
       " 'songs',\n",
       " 'pictures',\n",
       " 'games',\n",
       " 'books',\n",
       " 'movies',\n",
       " 'brings',\n",
       " 'bring',\n",
       " 'interests',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'near',\n",
       " 'next',\n",
       " 'side',\n",
       " 'front',\n",
       " 'across',\n",
       " 'behind',\n",
       " 'many',\n",
       " 'most',\n",
       " 'painting',\n",
       " 'movie',\n",
       " 'game',\n",
       " 'song',\n",
       " 'picture',\n",
       " 'novel',\n",
       " 'poem',\n",
       " 'show',\n",
       " 'by',\n",
       " 'book',\n",
       " 'famous',\n",
       " 'children',\n",
       " 'ignored',\n",
       " 'seen',\n",
       " 'said',\n",
       " 'thought',\n",
       " 'knew',\n",
       " 'mechanics',\n",
       " 'bankers',\n",
       " 'banker',\n",
       " 'mechanic',\n",
       " 'and',\n",
       " 'had',\n",
       " 'appreciated',\n",
       " 'gotten',\n",
       " 'appreciatedbeen',\n",
       " 'get',\n",
       " 'colleagues',\n",
       " 'day',\n",
       " 'every',\n",
       " 'journal',\n",
       " 'a',\n",
       " 'twenty',\n",
       " 'years',\n",
       " 'watch',\n",
       " 'with',\n",
       " 'tennis',\n",
       " 'playing',\n",
       " 'different',\n",
       " 'foreign',\n",
       " 'languages',\n",
       " 'three',\n",
       " 'television',\n",
       " 'knows',\n",
       " 'enjoy',\n",
       " 'writes',\n",
       " 'know',\n",
       " 'write',\n",
       " 'enjoys',\n",
       " 'some']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b9659474",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = KeyedVectors.load_word2vec_format('embedding.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e47f5352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14532\n"
     ]
    }
   ],
   "source": [
    "words = list(word2vec_model.index_to_key)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8d59a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of key-value pairs :  14532\n"
     ]
    }
   ],
   "source": [
    "word_vec_dict={}\n",
    "for word in words:\n",
    "    word_vec_dict[word]=word2vec_model.get_vector(word)\n",
    "print(\"The no of key-value pairs : \",len(word_vec_dict)) # should come equal to vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "951d8447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14532 300\n"
     ]
    }
   ],
   "source": [
    "w2v_weights = word2vec_model.vectors\n",
    "vocab_size, embedding_size = w2v_weights.shape\n",
    "print(vocab_size, embedding_size)\n",
    "MAX_SEQUENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7b0ca688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.initializers import Constant\n",
    "import gensim\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import logging\n",
    "import random\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e9187c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "37b99d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the author that the guard likes laughs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the author that the guard likes laugh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the author that the guard likes swims</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the author that the guard likes swim</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the author that the guard likes smiles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30253</th>\n",
       "      <td>some shows will ever be ignored</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30254</th>\n",
       "      <td>many shows will ever be ignored</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30255</th>\n",
       "      <td>few shows will ever get old</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30256</th>\n",
       "      <td>some shows will ever get old</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30257</th>\n",
       "      <td>many shows will ever get old</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324778 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Sentence  Judgement\n",
       "0      the author that the guard likes laughs           1\n",
       "1       the author that the guard likes laugh           0\n",
       "2       the author that the guard likes swims           1\n",
       "3        the author that the guard likes swim           0\n",
       "4      the author that the guard likes smiles           1\n",
       "...                                        ...        ...\n",
       "30253         some shows will ever be ignored           0\n",
       "30254         many shows will ever be ignored           0\n",
       "30255             few shows will ever get old           1\n",
       "30256            some shows will ever get old           0\n",
       "30257            many shows will ever get old           0\n",
       "\n",
       "[324778 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1714eedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "maxi=-1\n",
    "for i,rev in enumerate(df['Sentence']):\n",
    "  tokens=rev.split()\n",
    "  if(len(tokens)>maxi):\n",
    "    maxi=len(tokens)\n",
    "\n",
    "\n",
    "tok = Tokenizer(filters='')\n",
    "tok.fit_on_texts(df['Sentence'])\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "encd_rev = tok.texts_to_sequences(df['Sentence'])\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fb458896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1  71   2 ...   0   0   0]\n",
      " [  1  71   2 ...   0   0   0]\n",
      " [  1  71   2 ...   0   0   0]\n",
      " ...\n",
      " [ 82  91  34 ...   0   0   0]\n",
      " [162  91  34 ...   0   0   0]\n",
      " [111  91  34 ...   0   0   0]]\n",
      "(324778, 15)\n"
     ]
    }
   ],
   "source": [
    "pad_rev= pad_sequences(encd_rev, maxlen=maxi+1, padding='post')\n",
    "pad_rev.shape   # note that we had 100K reviews and we have padded each review to have  a lenght of 1565 words.\n",
    "print(pad_rev)\n",
    "print(pad_rev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3b7ead46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259822, 15)\n",
      "(259822, 2)\n",
      "(32478, 15)\n",
      "(32478, 2)\n",
      "(32478, 15)\n",
      "(32478, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now creating the embedding matrix\n",
    "embed_matrix=np.zeros(shape=(vocab_size,embedding_size))\n",
    "# print(len(tok.word_index.items()))\n",
    "for word,i in tok.word_index.items():\n",
    "  embed_vector=word_vec_dict.get(word)\n",
    "  if embed_vector is not None:  # word is in the vocabulary learned by the w2v model\n",
    "    embed_matrix[i]=embed_vector\n",
    "  # if word is not found then embed_vector corressponding to that vector will stay zero.\n",
    "\n",
    "train_size=0.8\n",
    "\n",
    "y = np.array(df['Judgement'].tolist())\n",
    "\n",
    "leinst = LabelEncoder()\n",
    "yinst = leinst.fit_transform(y)\n",
    "\n",
    "ycat = to_categorical(df['Judgement'])  # one hot target as required by NN\n",
    "# print(ycat)\n",
    "# X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "X_train, X_test, y_train, y_test = train_test_split(pad_rev, ycat, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "# test_size = 0.5\n",
    "# X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_test, y_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "print(X_train.shape), print(y_train.shape)\n",
    "print(X_validation.shape), print(y_validation.shape)\n",
    "print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "750a8bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(leinst.classes_)\n",
    "print(num_classes)\n",
    "print(leinst.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b5c2a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14532, 300)\n"
     ]
    }
   ],
   "source": [
    "print(w2v_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f8146174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation[20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a6417531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4060/4060 [==============================] - 50s 12ms/step - loss: 0.0586 - accuracy: 0.9644 - val_loss: 8.7534e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "4060/4060 [==============================] - 50s 12ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 6.2334e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "4060/4060 [==============================] - 50s 12ms/step - loss: 2.6350e-05 - accuracy: 1.0000 - val_loss: 7.1157e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "4060/4060 [==============================] - 52s 13ms/step - loss: 2.8599e-06 - accuracy: 1.0000 - val_loss: 7.7508e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "4060/4060 [==============================] - 55s 14ms/step - loss: 3.2377e-07 - accuracy: 1.0000 - val_loss: 9.7935e-08 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Keras Embedding layer with Word2Vec weights initialization\n",
    "model.add(Embedding(input_dim=vocab_size,\n",
    "                    output_dim=embedding_size,\n",
    "                    weights=[embed_matrix],\n",
    "                    input_length=15,\n",
    "                    ))\n",
    "\n",
    "model.add(Bidirectional(LSTM(30)))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# model.add(Flatten())\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64,\n",
    "                    validation_data=(X_validation, y_validation), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a85999e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 9.778363363466269e-08 / Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "91020e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,  52,   2, ...,   0,   0,   0],\n",
       "       [  1,  61,   2, ...,   0,   0,   0],\n",
       "       [  1, 121,   2, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  1,  92,   2, ...,   0,   0,   0],\n",
       "       [  1,  53,   2, ...,   0,   0,   0],\n",
       "       [  1,  61, 106, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4dcfb64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f98736c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 6.4676736e-17],\n",
       "       [5.4803032e-15, 1.0000000e+00],\n",
       "       [1.0000000e+00, 1.4890333e-14],\n",
       "       ...,\n",
       "       [1.0000000e+00, 1.0264168e-14],\n",
       "       [2.6144365e-14, 1.0000000e+00],\n",
       "       [1.0000000e+00, 2.6892684e-15]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1eecf17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  1\n"
     ]
    }
   ],
   "source": [
    "n = random.randint(0, len(y_test))\n",
    "i = np.argmax(predictions[n])\n",
    "print(\"Prediction: \", leinst.classes_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c180d4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20222"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4234669a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 71,  2,  1, 38, 13, 89, 46,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf08ce3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
